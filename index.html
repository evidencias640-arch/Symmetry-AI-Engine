<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>SYMMETRY AI ENGINE PRO V4 ‚Äî Capture & Analyze</title>

  <!-- Tailwind (visual) -->
  <script src="https://cdn.tailwindcss.com"></script>

  <style>
    @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@600;800&family=Inter:wght@300;400;600&display=swap');

    :root{
      --ia:#00ffff;
      --ia-2:#66ffff;
      --bg:#0d1117;
      --muted:#9aa4b2;
      --error:#ff3366;
    }

    html,body{height:100%}
    body{
      margin:0;
      background:linear-gradient(180deg,#071018 0%, #0d1117 60%);
      color:#cfeff2;
      font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,"Helvetica Neue",Arial;
      -webkit-font-smoothing:antialiased;
      -moz-osx-font-smoothing:grayscale;
      padding:16px;
    }

    h1,h2{font-family:Orbitron,Inter,Arial}
    .ia-border{
      border:1px solid rgba(0,255,255,0.15);
      box-shadow:0 6px 30px rgba(0,255,255,0.04), inset 0 0 10px rgba(0,255,255,0.02);
      background:linear-gradient(180deg, rgba(10,18,25,0.6), rgba(7,11,18,0.5));
    }

    /* capture area */
    .capture-wrap{position:relative; overflow:hidden; border-radius:14px}
    #webcam-feed, #capture-canvas{
      width:100%;
      height:100%;
      object-fit:cover;
      display:block;
      position:absolute; top:0; left:0;
    }
    #capture-canvas{z-index:2; pointer-events:none}
    #webcam-feed{z-index:1}

    /* placeholder overlay */
    #placeholder-message{
      position:absolute; z-index:3; inset:0;
      display:flex; align-items:center; justify-content:center; flex-direction:column;
      gap:8px; text-align:center; padding:18px;
      background:linear-gradient(180deg, rgba(2,6,10,0.55), rgba(7,11,18,0.45));
      color:var(--ia);
    }

    /* controls */
    .controls{display:flex; gap:10px; flex-wrap:wrap; justify-content:center; margin-top:12px}
    .btn{
      background:#071826; color:var(--ia); border:1px solid rgba(0,255,255,0.08);
      padding:12px 18px; border-radius:12px; font-weight:600; cursor:pointer;
      transition:transform .14s ease, box-shadow .14s ease, background .14s ease;
      box-shadow:0 6px 18px rgba(0,255,255,0.03);
    }
    .btn:active{transform:translateY(1px)}
    .btn.primary{background:linear-gradient(90deg,var(--ia),var(--ia-2)); color:#032024; font-weight:800}
    .btn.ghost{background:transparent; border:1px dashed rgba(255,255,255,0.03); color:#cfeff2}

    /* progress bar */
    .progress-wrap{height:10px; background:rgba(255,255,255,0.03); border-radius:999px; overflow:hidden}
    .progress-bar{height:100%; width:0%; background:linear-gradient(90deg,var(--ia),var(--ia-2)); transition:width .4s cubic-bezier(.2,.7,.2,1)}

    /* results card */
    .results {
      margin-top:12px; padding:14px; border-radius:12px; background:linear-gradient(180deg, rgba(3,6,10,0.55), rgba(7,11,18,0.6));
      box-shadow:0 8px 30px rgba(0,0,0,0.5); border:1px solid rgba(0,255,255,0.04);
    }

    /* animated score */
    .score {
      font-family:Orbitron,Inter,Arial; font-weight:800; font-size:40px; color:#fff;
      text-shadow:0 6px 30px rgba(0,255,255,0.06);
      transform-origin:center; transition:transform .8s cubic-bezier(.2,.7,.2,1);
    }

    /* mobile superlarge face for <300px */
    @media (max-width:300px){
      #capture-canvas, #webcam-feed {
        transform:scale(1.25);
        transform-origin:center center;
      }
      .btn{padding:10px 12px; font-size:13px}
      .score{font-size:30px}
    }

    /* small animation helpers */
    .fade-in{animation:fadeIn .3s ease both}
    @keyframes fadeIn{from{opacity:0; transform:translateY(6px)} to{opacity:1; transform:none}}
  </style>
</head>
<body>

  <main class="max-w-4xl mx-auto">
    <header class="text-center mb-8">
      <h1 class="text-4xl md:text-5xl font-extrabold">SYMMETRY <span style="color:var(--ia-2)">AI</span> ENGINE</h1>
      <p class="text-sm text-muted mt-2" style="color:var(--muted)">Capture ‚Üí Freeze ‚Üí Analyze ‚Äî Pro Mode</p>
    </header>

    <!-- capture panel -->
    <section class="ia-border p-4 md:p-6 rounded-xl">
      <div class="grid md:grid-cols-3 gap-4">
        <!-- left: capture viewport -->
        <div class="md:col-span-2">
          <div id="capture-area" class="capture-wrap aspect-[16/9] ia-border">
            <video id="webcam-feed" autoplay muted playsinline></video>
            <canvas id="capture-canvas"></canvas>

            <div id="placeholder-message">
              <svg width="56" height="56" viewBox="0 0 24 24" fill="none"><path d="M3 7a2 2 0 0 1 2-2h1l.72-1.08A2 2 0 0 1 9.72 3h4.56a2 2 0 0 1 1.99 1.92L17.28 5H19a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V7z" stroke="currentColor" stroke-width="1.2" stroke-linecap="round" stroke-linejoin="round"/></svg>
              <strong style="font-size:16px">SUBSISTEMA INACTIVO</strong>
              <span style="color:var(--muted); font-size:13px">Active la c√°mara y presione <em>CAPTURAR ROSTRO</em>.</span>
            </div>
          </div>

          <div class="controls mt-4">
            <button id="btn-start-live" class="btn">üî¥ Iniciar C√°mara</button>
            <button id="capture-btn" class="btn primary" disabled>üì∏ CAPTURAR ROSTRO</button>
            <button id="analyze-btn" class="btn" style="display:none">‚öôÔ∏è ANALIZAR / PROCESAR</button>
            <button id="download-btn" class="btn ghost" style="display:none">‚¨áÔ∏è DESCARGAR</button>
            <button id="btn-retry" class="btn" style="display:none">üîÑ VOLVER A LIVE</button>
          </div>

          <div class="mt-3" id="live-status" style="color:var(--muted); font-size:13px">Estado: <span id="status-text">apagado</span></div>
        </div>

        <!-- right: results -->
        <div class="md:col-span-1">
          <div class="results">
            <div class="flex items-center justify-between">
              <div>
                <div style="font-size:12px; color:var(--muted)">RESULTADO</div>
                <div id="score" class="score">‚Äî</div>
              </div>
              <div style="text-align:right">
                <div style="font-size:12px; color:var(--muted)">DETECCIONES</div>
                <div id="det-count" style="font-weight:700; font-size:20px">0</div>
              </div>
            </div>

            <div style="margin-top:12px">
              <div style="font-size:12px; color:var(--muted); margin-bottom:6px">Barra de proceso</div>
              <div class="progress-wrap"><div id="progress" class="progress-bar"></div></div>
            </div>

            <div id="expressions" style="margin-top:12px; font-size:13px; color:var(--muted)">
              No analizado
            </div>

            <div id="analysis-log" style="margin-top:12px; font-size:12px; color:var(--muted)"></div>
          </div>
        </div>
      </div>
    </section>

    <!-- Alert panel -->
    <div id="alert-message" class="fixed inset-0 hidden items-center justify-center p-4 z-50">
      <div class="bg-[#071018] p-4 rounded-md border border-1" style="border-left:4px solid var(--error); max-width:520px">
        <div style="color:var(--error); font-weight:700">ERROR</div>
        <div id="alert-text" style="color:#fff; margin-top:8px"></div>
        <div style="margin-top:12px; text-align:right">
          <button onclick="document.getElementById('alert-message').classList.add('hidden')" class="btn">OK</button>
        </div>
      </div>
    </div>

  </main>

  <!-- face-api local script (must be present in same folder) -->
  <script src="./face-api.min.js"></script>

  <script>
  // ============================
  // CONFIG / ELEMENTS
  // ============================
  const MODELS_URL = './models';
  const vid = document.getElementById('webcam-feed');
  const canvas = document.getElementById('capture-canvas');
  const ctx = canvas.getContext('2d');

  const btnStart = document.getElementById('btn-start-live');
  const captureBtn = document.getElementById('capture-btn');
  const analyzeBtn = document.getElementById('analyze-btn');
  const downloadBtn = document.getElementById('download-btn');
  const btnRetry = document.getElementById('btn-retry');

  const placeholder = document.getElementById('placeholder-message');
  const statusText = document.getElementById('status-text');
  const progressBar = document.getElementById('progress');
  const scoreEl = document.getElementById('score');
  const detCount = document.getElementById('det-count');
  const expressionsEl = document.getElementById('expressions');
  const logEl = document.getElementById('analysis-log');

  const alertBox = document.getElementById('alert-message');
  const alertText = document.getElementById('alert-text');

  let stream = null;
  let rafId = null;
  let running = false;
  let capturedImageDataUrl = null;
  let lastDetections = [];

  function showAlert(msg){
    alertText.textContent = msg;
    alertBox.classList.remove('hidden');
  }

  // ============================
  // LOAD MODELS (local)
  // ============================
  async function loadModels() {
    try {
      statusText.textContent = 'Cargando modelos...';
      await Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri(MODELS_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODELS_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODELS_URL)
      ]);
      statusText.textContent = 'Modelos listos';
      btnStart.disabled = false;
    } catch (e) {
      console.error(e);
      showAlert('No se pudieron cargar los modelos: ' + e.message);
    }
  }

  // ============================
  // START CAMERA / LIVE LOOP
  // ============================
  async function startCamera(){
    try {
      stream = await navigator.mediaDevices.getUserMedia({ video: { width: { ideal: 1280 }, height: { ideal: 720 } }, audio: false });
      vid.srcObject = stream;
      await vid.play();

      // hide placeholder
      placeholder.style.display = 'none';
      statusText.textContent = 'Live: conectado';
      captureBtn.disabled = false;
      btnStart.disabled = true;
      btnRetry.style.display = 'none';
      analyzeBtn.style.display = 'none';
      downloadBtn.style.display = 'none';

      resizeCanvasToVideo();
      running = true;
      requestAnimationFrame(liveLoop);
    } catch(err) {
      console.error(err);
      showAlert('No se pudo acceder a la c√°mara: ' + err.message);
    }
  }

  function resizeCanvasToVideo(){
    // Ajusta tama√±o real del canvas tomando en cuenta pantallas peque√±as <300
    const vw = vid.videoWidth || vid.clientWidth || 640;
    const vh = vid.videoHeight || vid.clientHeight || 360;
    // Si pantalla muy peque√±a, vamos a escalar para que el rostro se vea grande
    const screenW = window.innerWidth;
    let targetW = vw;
    if(screenW < 300){
      targetW = Math.min(vw, Math.max(screenW * 0.95, 240)); // aseg√∫rate tama√±o visible
    } else {
      targetW = Math.min(vw, 960);
    }
    // Mantener aspecto proporcional
    const ratio = vh / vw;
    canvas.width = Math.round(targetW);
    canvas.height = Math.round(targetW * ratio);
    // also set CSS height to fill parent
    canvas.style.width = '100%';
    canvas.style.height = '100%';
  }

  async function liveLoop(){
    if(!running) return;
    try {
      resizeCanvasToVideo();

      // detection on video (fast)
      const detections = await faceapi.detectAllFaces(vid, new faceapi.SsdMobilenetv1Options({minConfidence:0.5}))
                        .withFaceLandmarks().withFaceExpressions();

      // clear and draw current frame and overlays
      ctx.clearRect(0,0,canvas.width,canvas.height);
      // draw video frame scaled to canvas
      ctx.drawImage(vid, 0, 0, canvas.width, canvas.height);

      // map detection coordinates to current canvas size
      const displaySize = { width: vid.videoWidth, height: vid.videoHeight };
      const resized = faceapi.resizeResults(detections, { width: canvas.width, height: canvas.height });

      // draw overlays using face-api draw utilities (but use our canvas ctx)
      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceLandmarks(canvas, resized);
      faceapi.draw.drawFaceExpressions(canvas, resized);

      // feedback
      detCount.textContent = detections.length;
      lastDetections = resized;

      // subtle progress animation when face present
      if(detections.length > 0){
        progressBar.style.width = '24%';
      } else {
        progressBar.style.width = '4%';
      }

    } catch (e){
      console.warn('liveLoop error', e);
    }
    rafId = requestAnimationFrame(liveLoop);
  }

  // ============================
  // CAPTURE (freeze frame) -> show analyze button
  // ============================
  captureBtn.addEventListener('click', ()=>{
    if(!vid.srcObject){
      showAlert('Primero inicia la c√°mara.');
      return;
    }
    // stop the live loop but keep stream active (pause video playback to freeze)
    running = false;
    if(rafId) cancelAnimationFrame(rafId);
    vid.pause();

    // draw final frozen frame into canvas (canvas already autosized)
    resizeCanvasToVideo();
    ctx.drawImage(vid, 0, 0, canvas.width, canvas.height);

    // store data url for download / analyze
    capturedImageDataUrl = canvas.toDataURL('image/png');

    // adjust controls
    analyzeBtn.style.display = 'inline-block';
    downloadBtn.style.display = 'inline-block';
    btnRetry.style.display = 'inline-block';
    captureBtn.disabled = true;
    statusText.textContent = 'Imagen capturada';
    progressBar.style.width = '40%';
    scoreElAnimate('--');
    expressionsEl.textContent = 'Listo para analizar';
    logEl.textContent = 'Presione "ANALIZAR / PROCESAR" para realizar el an√°lisis profesional.';
  });

  // ============================
  // ANALYZE: run accurate analysis on captured image
  // ============================
  analyzeBtn.addEventListener('click', async ()=>{
    if(!capturedImageDataUrl){
      showAlert('No hay imagen capturada para analizar.');
      return;
    }
    // UI start
    analyzeBtn.disabled = true;
    progressBar.style.width = '6%';
    logEl.textContent = '';
    statusText.textContent = 'Analizando...';
    expressionsEl.textContent = 'Calculando...';

    // animate progress to feel "professional"
    await animateProgressSequence([15, 40, 70, 95]);

    try {
      // run detection & landmarks & expressions ON the canvas (captured image)
      const dets = await faceapi.detectAllFaces(canvas, new faceapi.SsdMobilenetv1Options({minConfidence:0.5}))
                      .withFaceLandmarks().withFaceExpressions();

      // clear & redraw the capture (keep overlays)
      ctx.clearRect(0,0,canvas.width,canvas.height);
      // draw image back
      const img = new Image();
      img.src = capturedImageDataUrl;
      await new Promise(r => img.onload = r);
      ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

      const resized = faceapi.resizeResults(dets, { width: canvas.width, height: canvas.height });
      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceLandmarks(canvas, resized);
      faceapi.draw.drawFaceExpressions(canvas, resized);

      // update results
      detCount.textContent = dets.length;
      if(dets.length === 0){
        scoreElAnimate('‚Äî');
        expressionsEl.textContent = 'No se detect√≥ rostro en la captura.';
        logEl.textContent = 'Intente otra captura con mejor iluminaci√≥n y centrado.';
        progressBar.style.width = '100%';
        analyzeBtn.disabled = false;
        statusText.textContent = 'Analizado: 0 rostros';
        return;
      }

      // compute a simple "IFA-like" score (simetr√≠a aproximada)
      const score = computeItaScore(dets[0]);
      scoreElAnimate(score.toFixed(2));

      // expressions probabilities
      const expr = dets[0].expressions || {};
      expressionsEl.innerHTML = '<strong>Expresiones:</strong><br/>' + Object.entries(expr)
        .map(([k,v]) => `${k}: ${(v*100).toFixed(0)}%`).join('<br/>');

      progressBar.style.width = '100%';
      logEl.textContent = 'An√°lisis completado con √©xito.';
      statusText.textContent = 'Analizado';

    } catch(e){
      console.error(e);
      showAlert('Error durante el an√°lisis: ' + e.message);
      logEl.textContent = 'Fallo en la etapa de an√°lisis.';
    } finally {
      analyzeBtn.disabled = false;
    }
  });

  // progress animation helper
  async function animateProgressSequence(steps){
    for(const p of steps){
      progressBar.style.width = p + '%';
      await new Promise(r => setTimeout(r, 300));
    }
  }

  // compute a simple "symmetry" score using landmarks (0..100)
  function computeItaScore(detection){
    try {
      const lm = detection.landmarks;
      // average distance left eye to nose vs right eye to nose (normalized)
      const leftEye = centroid(lm.getLeftEye());
      const rightEye = centroid(lm.getRightEye());
      const nose = centroid(lm.getNose());
      const mouth = centroid(lm.getMouth());

      const dL = distance(leftEye, nose);
      const dR = distance(rightEye, nose);
      const eyeBalance = 1 - Math.abs(dL - dR) / Math.max(dL,dR);

      // mouth symmetry with respect to nose
      const dM = Math.abs(mouth.x - nose.x);
      const faceWidth = distance(lm.getLeftCheek ? centroid(lm.getLeftCheek()) : leftEye, lm.getRightCheek ? centroid(lm.getRightCheek()) : rightEye);
      const mouthBalance = 1 - Math.min(1, dM / (faceWidth*0.2 || 1));

      // combined score
      const raw = (eyeBalance * 0.6 + mouthBalance * 0.4) * 100;
      return Math.max(0, Math.min(100, raw));
    } catch(e){
      return 0;
    }
  }
  function centroid(points){
    const n = points.length;
    const s = points.reduce((acc,p)=>({x:acc.x+p.x, y:acc.y+p.y}), {x:0,y:0});
    return {x:s.x/n, y:s.y/n};
  }
  function distance(a,b){
    const dx = a.x - b.x, dy = a.y - b.y;
    return Math.sqrt(dx*dx + dy*dy);
  }

  // display score with small animation
  function scoreElAnimate(val){
    scoreEl = document.getElementById('score');
    scoreEl.style.transform = 'scale(0.88)';
    setTimeout(()=>{ scoreEl.textContent = val; scoreEl.style.transform = 'scale(1)'; }, 160);
  }

  // download captured PNG
  downloadBtn.addEventListener('click', ()=>{
    if(!capturedImageDataUrl){
      showAlert('No hay captura para descargar.');
      return;
    }
    const a = document.createElement('a');
    a.href = capturedImageDataUrl;
    a.download = 'captura_symmetry.png';
    document.body.appendChild(a);
    a.click();
    a.remove();
  });

  // retry / go back to live
  btnRetry.addEventListener('click', ()=>{
    // resume video playback and live loop
    if(vid.srcObject){
      vid.play();
      running = true;
      captureBtn.disabled = false;
      analyzeBtn.style.display = 'none';
      downloadBtn.style.display = 'none';
      btnRetry.style.display = 'none';
      statusText.textContent = 'Live: conectado';
      progressBar.style.width = '4%';
      requestAnimationFrame(liveLoop);
    } else {
      statusText.textContent = 'Sin c√°mara';
    }
  });

  // initial sequence
  window.addEventListener('load', async ()=>{
    // try to load models; enable start when ready
    await loadModels();
  });

  // enable start button
  btnStart.addEventListener('click', startCamera);

  // responsive: adjust canvas on resize
  window.addEventListener('resize', ()=>{ if(vid && vid.srcObject) resizeCanvasToVideo(); });

  </script>
</body>
</html>
